{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import LSTM_Prep\n",
    "\n",
    "# Data\n",
    "dat = pd.read_csv('forex.csv')\n",
    "\n",
    "split = 0.8\n",
    "sequence_length = 60\n",
    "\n",
    "data_prep = LSTM_Prep.Data_Prep(dataset = dat)\n",
    "rnn_df, validation_df = data_prep.preprocess_rnn(date_colname = 'date', numeric_colname = 'perc', pred_set_timesteps = 60)\n",
    "\n",
    "\n",
    "series_prep = LSTM_Prep.Series_Prep(rnn_df =  rnn_df, numeric_colname = 'perc')\n",
    "window, X_min, X_max = series_prep.make_window(sequence_length = sequence_length, \n",
    "                                               train_test_split = split, \n",
    "                                               return_original_x = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = series_prep.reshape_window(window, train_test_split = split)\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n",
    "#                 Building the LSTM\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import ReduceLROnPlateau #Learning rate scheduler for when we reach plateaus\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=100)\n",
    "\n",
    "# Reset model if we want to re-train with different splits\n",
    "def reset_weights(model):\n",
    "    import keras.backend as K\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'): \n",
    "            layer.kernel.initializer.run(session=session)\n",
    "        if hasattr(layer, 'bias_initializer'):\n",
    "            layer.bias.initializer.run(session=session)  \n",
    "\n",
    "\n",
    "# Epochs and validation split\n",
    "EPOCHS = 201\n",
    "validation = 0.05\n",
    "\n",
    "# Instantiate the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer.... the input shape is (Sample, seq_len-1, 1)\n",
    "model.add(LSTM(\n",
    "        input_shape = (sequence_length-1, 1), return_sequences = True,\n",
    "        units = 100))\n",
    "\n",
    "# Add the second layer.... the input shape is (Sample, seq_len-1, 1)\n",
    "model.add(LSTM(\n",
    "        input_shape = (sequence_length-1, 1), \n",
    "        units = 100))\n",
    "\n",
    "# Add the output layer, simply one unit\n",
    "model.add(Dense(\n",
    "        units = 1,\n",
    "        activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "\n",
    "\n",
    "# History object for plotting our model loss by epoch\n",
    "history = model.fit(X_train, y_train, epochs = EPOCHS, validation_split = validation,\n",
    "          callbacks = [rlrop])\n",
    "# Loss History\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n",
    "#              Predicting the future\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n",
    "# Creating our future object\n",
    "future = LSTM_Prep.Predict_Future(X_test  = X_test, validation_df = validation_df, lstm_model = model)\n",
    "# Checking its accuracy on our training set\n",
    "future.predicted_vs_actual(X_min = X_min, X_max = X_max, numeric_colname = 'perc')\n",
    "# Predicting 'x' timesteps out\n",
    "future.predict_future(X_min = X_min, X_max = X_max, numeric_colname = 'perc', timesteps_to_predict = 15, return_future = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time_series #custom TS methods\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "class Data_Prep:\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    \n",
    "    def preprocess_rnn(self, date_colname, numeric_colname, pred_set_timesteps):\n",
    "        features = (time_series.create_series(self.dataset, numeric_colname, date_colname)).sort_index()\n",
    "        rnn_df = features.groupby(features.index).sum()\n",
    "        \n",
    "        # Filter out 'n' timesteps for prediction purposes\n",
    "        timestep_idx = len(rnn_df)-pred_set_timesteps\n",
    "        validation_df = rnn_df.iloc[timestep_idx:]\n",
    "        rnn_df = rnn_df.iloc[1:timestep_idx,]\n",
    "        \n",
    "        # Dickey Fuller Test\n",
    "        print(\"Summary Statistics - ADF Test For Stationarity\\n\")\n",
    "        if time_series.stationarity_test(X = rnn_df[numeric_colname], return_p=True, print_res = False) > 0.05:\n",
    "            print(\"P Value is high. Consider Differencing: \" + str(time_series.stationarity_test(X = rnn_df[numeric_colname], return_p = True, print_res = False)))\n",
    "        else:\n",
    "            time_series.stationarity_test(X = rnn_df[numeric_colname])\n",
    "        \n",
    "        # Sorting\n",
    "        rnn_df = rnn_df.sort_index(ascending = True)\n",
    "        rnn_df = rnn_df.reset_index()\n",
    "        \n",
    "        return rnn_df, validation_df\n",
    "    \n",
    "    \n",
    "class Series_Prep:\n",
    "    \n",
    "    def __init__(self, rnn_df, numeric_colname):\n",
    "        self.rnn_df = rnn_df\n",
    "        self.numeric_colname = numeric_colname\n",
    "\n",
    "    def make_window(self, sequence_length, train_test_split, return_original_x = True):\n",
    "        \n",
    "        # Create the initial results df with a look_back of 60 days\n",
    "        result = []\n",
    "        \n",
    "        # 3D Array\n",
    "        for index in range(len(self.rnn_df) - sequence_length):\n",
    "            result.append(self.rnn_df[self.numeric_colname][index: index + sequence_length])  \n",
    "        \n",
    "        # Getting the initial train_test split for our min/max val scalar\n",
    "        train_test_split = 0.9\n",
    "        row = int(round(train_test_split * np.array(result).shape[0]))\n",
    "        train = np.array(result)[:row, :]\n",
    "        X_train = train[:, :-1]\n",
    "        \n",
    "        # Manual MinMax Scaler\n",
    "        X_min = X_train.min()\n",
    "        X_max = X_train.max()\n",
    "        \n",
    "        # keep the originals in case\n",
    "        X_min_orig = X_train.min()\n",
    "        X_max_orig = X_train.max()\n",
    "        \n",
    "        # Minmax scaler and a reverse method\n",
    "        def minmax(X):\n",
    "            return (X-X_min) / (X_max - X_min)\n",
    "        \n",
    "        def reverse_minmax(X):\n",
    "            return X * (X_max-X_min) + X_min\n",
    "        \n",
    "        # Method for Scaler for each window in our 3D array\n",
    "        def minmax_windows(window_data):\n",
    "            normalised_data = []\n",
    "            for window in window_data:\n",
    "                window.index = range(sequence_length)\n",
    "                normalised_window = [((minmax(p))) for p in window]\n",
    "                normalised_data.append(normalised_window)\n",
    "            return normalised_data\n",
    "        \n",
    "        # minmax the windows\n",
    "        result = minmax_windows(result)\n",
    "        # Convert to 2D array\n",
    "        result = np.array(result)\n",
    "        if return_original_x:\n",
    "            return result, X_min_orig, X_max_orig\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "    @staticmethod\n",
    "    def reshape_window(window, train_test_split = 0.8):\n",
    "        # Train/test for real this time\n",
    "        row = round(train_test_split * window.shape[0])\n",
    "        train = window[:row, :]\n",
    "        \n",
    "        # Get the sets\n",
    "        X_train = train[:, :-1]\n",
    "        y_train = train[:, -1]\n",
    "        X_test = window[row:, :-1]\n",
    "        y_test = window[row:, -1]\n",
    "        \n",
    "        # Reshape for LSTM\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        y_train = np.reshape(y_train, (-1,1))\n",
    "        y_test = np.reshape(y_test, (-1,1))\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "class Predict_Future:\n",
    "\n",
    "\n",
    "    def __init__(self, X_test, validation_df, lstm_model):\n",
    "        self.X_test = X_test\n",
    "        self.validation_df = validation_df\n",
    "        self.lstm_model = lstm_model\n",
    "        \n",
    "    def predicted_vs_actual(self, X_min, X_max, numeric_colname):\n",
    "        \n",
    "        curr_frame = self.X_test[len(self.X_test)-1]\n",
    "        future = []\n",
    "        \n",
    "        for i in range(len(self.validation_df)):\n",
    "              # append the prediction to our empty future list\n",
    "             future.append(self.lstm_model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "              # insert our predicted point to our current frame\n",
    "             curr_frame = np.insert(curr_frame, len(self.X_test[0]), future[-1], axis=0)\n",
    "              # push the frame up one to make it progress into the future\n",
    "             curr_frame = curr_frame[1:]\n",
    "        \n",
    "        def reverse_minmax(X, X_max = X_max, X_min = X_min):\n",
    "            return X * (X_max-X_min) + X_min\n",
    "\n",
    "        # Plot \n",
    "        reverse_curr_frame = pd.DataFrame({numeric_colname: [reverse_minmax(x) for x in self.X_test[len(self.X_test)-1]],\n",
    "                                           \"historical_flag\":1})\n",
    "        reverse_future = pd.DataFrame({numeric_colname: [reverse_minmax(x) for x in future],\n",
    "                                           \"historical_flag\":0})\n",
    "        \n",
    "        # Change the indicies! Only for FUTURE predictions\n",
    "        # reverse_future.index += len(reverse_curr_frame)\n",
    "        \n",
    "        print(\"See Plot for predicted vs. actuals\")\n",
    "        plt.plot(reverse_curr_frame[numeric_colname])\n",
    "        plt.plot(reverse_future[numeric_colname])\n",
    "        plt.title(\"Predicted Points Vs. Actuals (Validation)\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Check accuracy vs. actuals\n",
    "        comparison_df = pd.DataFrame({\"Validation\": self.validation_df[numeric_colname],\n",
    "                                      \"Predicted\": [reverse_minmax(x) for x in future]})\n",
    "        print(\"Validation Vs. Predicted\")\n",
    "        print(comparison_df.sum())\n",
    "        \n",
    "        \n",
    "    def predict_future(self, X_min, X_max, numeric_colname, timesteps_to_predict, return_future = True):\n",
    "    \n",
    "        curr_frame = self.X_test[len(self.X_test)-1]\n",
    "        future = []\n",
    "        \n",
    "        for i in range(timesteps_to_predict):\n",
    "              # append the prediction to our empty future list\n",
    "             future.append(self.lstm_model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "              # insert our predicted point to our current frame\n",
    "             curr_frame = np.insert(curr_frame, len(self.X_test[0]), future[-1], axis=0)\n",
    "              # push the frame up one to make it progress into the future\n",
    "             curr_frame = curr_frame[1:]\n",
    "        \n",
    "        def reverse_minmax(X, X_max = X_max, X_min = X_min):\n",
    "            return X * (X_max-X_min) + X_min\n",
    "\n",
    "        # Reverse the original frame and the future frame\n",
    "        reverse_curr_frame = pd.DataFrame({numeric_colname: [reverse_minmax(x) for x in self.X_test[len(self.X_test)-1]],\n",
    "                                           \"historical_flag\":1})\n",
    "        reverse_future = pd.DataFrame({numeric_colname: [reverse_minmax(x) for x in future],\n",
    "                                           \"historical_flag\":0})\n",
    "        \n",
    "        # Change the indicies to show prediction next to the actuals in orange\n",
    "        reverse_future.index += len(reverse_curr_frame)\n",
    "        \n",
    "        print(\"See Plot for Future Predictions\")\n",
    "        plt.plot(reverse_curr_frame[numeric_colname])\n",
    "        plt.plot(reverse_future[numeric_colname])\n",
    "        plt.title(\"Predicted Future of \"+ str(timesteps_to_predict) + \" days\")\n",
    "        plt.show()\n",
    "        \n",
    "        if return_future:\n",
    "            return reverse_future"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
